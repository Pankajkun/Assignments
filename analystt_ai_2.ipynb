{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMwfQtuSish37PHPleOzuw/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qjfnsANwLmpA","executionInfo":{"status":"ok","timestamp":1690123035410,"user_tz":-330,"elapsed":6511,"user":{"displayName":"Pankaj Ojha","userId":"08130538789285651973"}},"outputId":"9009cd98-8885-4883-c796-affaf0d7e404"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.27.1)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.11.2)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (1.26.16)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2023.5.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.4.1)\n"]}],"source":["pip install requests beautifulsoup4"]},{"cell_type":"code","source":["import requests\n","from bs4 import BeautifulSoup\n","import csv\n","import time\n","\n","# Base URL for the product listings\n","base_url = \"https://www.amazon.in/s?k=bags&crid=2M096C61O4MLT&qid=1653308124&sprefix=ba%2Caps%2C283&ref=sr_pg_\"\n","\n","# Number of pages to scrape\n","num_pages = 20\n","\n","# Initialize a list to store the scraped data\n","all_products = []\n","\n","# Function to scrape individual product pages and extract additional information\n","def scrape_product_page(product_url):\n","    headers = {\n","    'Accept-Language': 'en-US,en;q=0.9',\n","    'authority': 'www.amazon.com',\n","\n","    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36',\n","\n","}\n","\n","    response = requests.get(product_url, headers=headers)\n","\n","    if response.status_code == 200:\n","        soup = BeautifulSoup(response.text, \"html.parser\")\n","\n","        # Extract additional product details from the soup\n","        # Modify these selectors according to the actual structure of the product page\n","        description = soup.select_one(\"#productDescription\").get_text(strip=True).strip() if soup.select_one(\"#productDescription\") else \"N/A\"\n","        asin = soup.select_one(\"[data-asin]\")[\"data-asin\"].strip() if soup.select_one(\"[data-asin]\") else \"N/A\"\n","        product_description = soup.select_one(\"#productTitle\").get_text(strip=True).strip() if soup.select_one(\"#productTitle\") else \"N/A\"\n","        manufacturer = soup.select_one(\"#bylineInfo\").get_text(strip=True).strip() if soup.select_one(\"#bylineInfo\") else \"N/A\"\n","\n","        return description, asin, product_description, manufacturer\n","    else:\n","        print(f\"Failed to retrieve product page. Status code: {response.status_code}\")\n","        return \"N/A\", \"N/A\", \"N/A\", \"N/A\"\n","\n","# Loop through the pages\n","for page in range(1, num_pages + 1):\n","    url = f\"{base_url}{page}\"\n","    headers = {\n","        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3\"}\n","\n","    response = requests.get(url, headers=headers)\n","\n","    # Retry mechanism to handle 503 Service Unavailable errors\n","    max_retries = 3\n","    retries = 0\n","    while response.status_code == 503 and retries < max_retries:\n","        print(f\"Failed to retrieve page {page}. Retrying...\")\n","        time.sleep(5)  # Wait for 5 seconds before retrying\n","        response = requests.get(url, headers=headers)\n","        retries += 1\n","\n","    if response.status_code == 200:\n","        soup = BeautifulSoup(response.text, \"html.parser\")\n","\n","        # Extract product information from the soup\n","        products = soup.select(\".s-result-item\")\n","\n","        for product in products:\n","            try:\n","                # Extracting product details\n","                product_url_element = product.select_one(\".s-line-clamp-2 a\")\n","                if product_url_element:\n","                    product_url = \"https://www.amazon.in\" + product_url_element['href']\n","                else:\n","                    product_url = \"N/A\"\n","\n","                product_name_element = product.select_one(\".a-text-normal\")\n","                product_name = product_name_element.get_text(strip=True).strip() if product_name_element else \"N/A\"\n","\n","                product_price_element = product.select_one(\".a-offscreen\")\n","                product_price = product_price_element.get_text(strip=True).strip() if product_price_element else \"N/A\"\n","\n","                # Some products may not have a rating or number of reviews, so handle the possible absence of these elements\n","                rating_element = product.select_one(\".a-icon-star-small\")\n","                rating = rating_element.get_text(strip=True).strip() if rating_element else \"N/A\"\n","\n","                num_reviews_element = product.select_one(\".a-size-base\")\n","                num_reviews = num_reviews_element.get_text(strip=True).strip() if num_reviews_element else \"0\"\n","\n","                # Scrape the individual product page for additional information\n","                if product_url != \"N/A\":\n","                    description, asin, product_description, manufacturer = scrape_product_page(product_url)\n","                else:\n","                    description, asin, product_description, manufacturer = \"N/A\", \"N/A\", \"N/A\", \"N/A\"\n","\n","                # Add the extracted data to the all_products list as a dictionary\n","                all_products.append({\n","                    \"Product URL\": product_url,\n","                    \"Product Name\": product_name,\n","                    \"Product Price\": product_price,\n","                    \"Rating\": rating,\n","                    \"Number of reviews\": num_reviews,\n","                    \"Description\": description,\n","                    \"ASIN\": asin,\n","                    \"Product Description\": product_description,\n","                    \"Manufacturer\": manufacturer\n","                })\n","\n","                # Introduce a delay of 1 second between each request to avoid overwhelming the server\n","                time.sleep(1)\n","\n","            except Exception as e:\n","                print(f\"Error occurred while processing product on page {page}. Skipping the product.\")\n","                print(f\"Error: {e}\")\n","                continue\n","\n","    else:\n","        print(f\"Failed to retrieve page {page}. Status code: {response.status_code}\")\n","\n","# Save the data to a CSV file\n","csv_file = \"amazon_bags_data.csv\"\n","with open(csv_file, mode=\"w\", newline=\"\", encoding=\"utf-8\") as file:\n","    writer = csv.DictWriter(file, fieldnames=[\"Product URL\", \"Product Name\", \"Product Price\", \"Rating\", \"Number of reviews\", \"Description\", \"ASIN\", \"Product Description\", \"Manufacturer\"])\n","    writer.writeheader()\n","    writer.writerows(all_products)\n","\n","print(f\"Data successfully scraped and exported to {csv_file}.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RuXtMu6nLzBS","executionInfo":{"status":"ok","timestamp":1690128758046,"user_tz":-330,"elapsed":5115,"user":{"displayName":"Pankaj Ojha","userId":"08130538789285651973"}},"outputId":"711160a7-0c09-452d-c89e-a02c8060f6e7"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Failed to retrieve page 1. Retrying...\n","Failed to retrieve page 1. Retrying...\n","Failed to retrieve product page. Status code: 503\n","Failed to retrieve product page. Status code: 503\n","Failed to retrieve product page. Status code: 503\n","Failed to retrieve product page. Status code: 503\n","Failed to retrieve page 2. Retrying...\n","Failed to retrieve page 2. Retrying...\n","Failed to retrieve product page. Status code: 503\n","Failed to retrieve product page. Status code: 503\n","Failed to retrieve product page. Status code: 503\n","Failed to retrieve product page. Status code: 503\n","Failed to retrieve page 3. Retrying...\n","Failed to retrieve product page. Status code: 503\n","Failed to retrieve product page. Status code: 503\n","Failed to retrieve product page. Status code: 503\n","Failed to retrieve product page. Status code: 503\n","Failed to retrieve product page. Status code: 503\n","Failed to retrieve product page. Status code: 503\n","Failed to retrieve product page. Status code: 503\n","Failed to retrieve product page. Status code: 503\n","Failed to retrieve product page. Status code: 503\n","Failed to retrieve product page. Status code: 503\n","Failed to retrieve product page. Status code: 503\n","Failed to retrieve product page. Status code: 503\n","Failed to retrieve product page. Status code: 503\n","Failed to retrieve product page. Status code: 503\n","Failed to retrieve product page. Status code: 503\n","Failed to retrieve page 5. Retrying...\n","Failed to retrieve page 5. Retrying...\n","Failed to retrieve page 5. Retrying...\n","Failed to retrieve page 5. Status code: 503\n","Failed to retrieve page 6. Retrying...\n","Failed to retrieve page 6. Retrying...\n","Failed to retrieve page 6. Retrying...\n","Failed to retrieve page 6. Status code: 503\n","Failed to retrieve page 7. Retrying...\n","Failed to retrieve page 7. Retrying...\n","Failed to retrieve page 7. Retrying...\n","Failed to retrieve product page. Status code: 503\n","Failed to retrieve product page. Status code: 503\n","Failed to retrieve product page. Status code: 503\n","Failed to retrieve product page. Status code: 503\n","Failed to retrieve product page. Status code: 503\n","Failed to retrieve product page. Status code: 503\n","Failed to retrieve product page. Status code: 503\n","Failed to retrieve page 8. Retrying...\n","Failed to retrieve page 8. Retrying...\n","Failed to retrieve page 8. Retrying...\n","Failed to retrieve page 8. Status code: 503\n","Failed to retrieve page 9. Retrying...\n","Failed to retrieve page 9. Retrying...\n","Failed to retrieve page 9. Retrying...\n","Failed to retrieve page 9. Status code: 503\n","Failed to retrieve page 10. Retrying...\n","Failed to retrieve page 10. Retrying...\n","Failed to retrieve page 10. Retrying...\n","Failed to retrieve product page. Status code: 503\n","Failed to retrieve product page. Status code: 503\n","Failed to retrieve product page. Status code: 503\n","Failed to retrieve product page. Status code: 503\n","Failed to retrieve product page. Status code: 503\n","Failed to retrieve product page. Status code: 503\n","Failed to retrieve product page. Status code: 503\n","Failed to retrieve product page. Status code: 503\n","Failed to retrieve product page. Status code: 503\n","Failed to retrieve product page. Status code: 503\n","Failed to retrieve product page. Status code: 503\n","Failed to retrieve product page. Status code: 503\n","Failed to retrieve page 12. Retrying...\n","Failed to retrieve page 12. Retrying...\n","Failed to retrieve page 12. Retrying...\n","Failed to retrieve page 12. Status code: 503\n","Failed to retrieve page 13. Retrying...\n","Failed to retrieve page 13. Retrying...\n","Failed to retrieve page 13. Retrying...\n","Failed to retrieve page 13. Status code: 503\n","Failed to retrieve page 14. Retrying...\n","Failed to retrieve page 14. Retrying...\n","Failed to retrieve page 14. Retrying...\n","Failed to retrieve product page. Status code: 503\n","Failed to retrieve product page. Status code: 503\n","Failed to retrieve product page. Status code: 503\n","Failed to retrieve product page. Status code: 503\n","Failed to retrieve product page. Status code: 503\n","Failed to retrieve product page. Status code: 503\n","Failed to retrieve product page. Status code: 503\n","Failed to retrieve product page. Status code: 503\n","Failed to retrieve product page. Status code: 503\n","Failed to retrieve product page. Status code: 503\n","Failed to retrieve page 15. Retrying...\n","Failed to retrieve page 15. Retrying...\n","Failed to retrieve page 15. Retrying...\n","Failed to retrieve page 15. Status code: 503\n","Failed to retrieve page 16. Retrying...\n","Failed to retrieve page 16. Retrying...\n","Failed to retrieve product page. Status code: 503\n","Failed to retrieve product page. Status code: 503\n","Failed to retrieve product page. Status code: 503\n","Failed to retrieve product page. Status code: 503\n","Failed to retrieve product page. Status code: 503\n","Failed to retrieve product page. Status code: 503\n","Failed to retrieve product page. Status code: 503\n","Failed to retrieve product page. Status code: 503\n","Failed to retrieve product page. Status code: 503\n","Failed to retrieve product page. Status code: 503\n","Failed to retrieve product page. Status code: 503\n","Failed to retrieve product page. Status code: 503\n","Failed to retrieve page 17. Retrying...\n","Failed to retrieve page 17. Retrying...\n","Failed to retrieve page 17. Retrying...\n","Failed to retrieve product page. Status code: 503\n","Failed to retrieve product page. Status code: 503\n","Failed to retrieve product page. Status code: 503\n","Failed to retrieve product page. Status code: 503\n","Failed to retrieve product page. Status code: 503\n","Failed to retrieve product page. Status code: 503\n","Failed to retrieve product page. Status code: 503\n","Failed to retrieve product page. Status code: 503\n","Failed to retrieve product page. Status code: 503\n","Failed to retrieve page 18. Retrying...\n","Failed to retrieve page 18. Retrying...\n","Failed to retrieve page 18. Retrying...\n","Failed to retrieve page 18. Status code: 503\n","Failed to retrieve page 19. Retrying...\n","Failed to retrieve page 19. Retrying...\n","Failed to retrieve page 19. Retrying...\n","Failed to retrieve page 19. Status code: 503\n","Failed to retrieve page 20. Retrying...\n","Failed to retrieve page 20. Retrying...\n","Failed to retrieve page 20. Retrying...\n","Failed to retrieve page 20. Status code: 503\n","Data successfully scraped and exported to amazon_bags_data.csv.\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"QzuRqHZqObhG"},"execution_count":null,"outputs":[]}]}